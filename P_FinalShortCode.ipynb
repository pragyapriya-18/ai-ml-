{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEKMn15++lJEmusf4GGkq5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragyapriya-18/ai-ml-/blob/main/P_FinalShortCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "--#SHORT CODES FOR PR EXAM#--\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aO89gp3PhKLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**1.MNIST:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "XFEc2RKkhhGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess\n",
        "x_train = x_train.reshape(60000, 28*28) / 255\n",
        "x_test  = x_test.reshape(10000, 28*28) / 255\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=28*28, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# Train\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
        "\n",
        "# Test accuracy\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test Accuracy:\", acc)\n",
        "\n",
        "# Optional: Predict one sample\n",
        "y_pred = model.predict(x_test)\n",
        "print(\"Predicted digit:\", np.argmax(y_pred[0]))\n"
      ],
      "metadata": {
        "id": "DScuLN8YhfZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**2.AND LOGIC GATE:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Vmdrm8D4w7oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Load\n",
        "path = \"/content/drive/MyDrive/dataset/and.csv\"\n",
        "df= pd.read_csv(path)\n",
        "print(df)\n",
        "\n",
        "# Prepare\n",
        "x = df.iloc[:,:2].values\n",
        "y = df.iloc[:,2:].values\n",
        "print(y)\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "model.add(Dense(16,input_dim=2,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Train\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])\n",
        "model.fit(x,y,epochs=250)\n",
        "\n",
        "\n",
        "# Testing\n",
        "print(model.predict(np.array([[1, 1]])))\n",
        "\n",
        "weights = model.get_weights()\n",
        "print(weights[1])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vhHkHUbNxb2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**3.IRIS CLASSIFIER:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ctvQsBmK0Yf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X8O9PfBidxG",
        "outputId": "36ae01bd-951a-4a68-8027-762cee459bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Load\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = to_categorical(iris.target, num_classes=3)\n",
        "\n",
        "# Prepare\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=4, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Train\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=250)\n",
        "\n",
        "# Test\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "_uZmmB_x0XnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**4.HANDLING MISSING VALUES:--**\n",
        "\n",
        "---\n",
        "\n",
        "Using isnull() and notnull()\n",
        "\n",
        "Using fillna(),bfill(),pad()\n",
        "\n",
        "Interpolate the missing values\n",
        "\n",
        "Using dropna()"
      ],
      "metadata": {
        "id": "VnNP7A6Q0j-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Given the following data:\n",
        "\n",
        "Create a DateFrame for the above data\n",
        "\n",
        "   First Score       Second Score            Third Score\n",
        "\n",
        "0     100                30                     np.nan\n",
        "\n",
        "1     90                 45                       40\n",
        "\n",
        "2    np.nan              56                       80\n",
        "\n",
        "3      95               np.nan                    98\n"
      ],
      "metadata": {
        "id": "Ilhmhvj5gTbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "dict={'First Score':[100,90,np.nan,95],\n",
        "      'Second Score':[30,45,56,np.nan],\n",
        "      'Third Score':[np.nan,40,80,98]}\n",
        "df=pd.DataFrame(dict)\n",
        "print(df)\n",
        "\n",
        "df.isnull()\n",
        "df.notnull()\n",
        "\n",
        "df.fillna(0)\n",
        "df.fillna(method='pad')\n",
        "df.fillna(method='bfill')\n",
        "\n",
        "df.interpolate(method='linear',limit_direction='forward')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "dict={'First Score':[100,90,np.nan,95],\n",
        "      'Second Score':[30,np.nan,45,56],\n",
        "      'Third Score':[52,40,80,98],\n",
        "      'Fourth Score':[np.nan,np.nan,np.nan,65]}\n",
        "df=pd.DataFrame(dict)\n",
        "print(df)\n",
        "df.dropna()"
      ],
      "metadata": {
        "id": "eWxXu8jF0jU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**5.DECISION TREE CLASSIFIER:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "h0nBb6Qc0upQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load\n",
        "df=load_iris()\n",
        "\n",
        "x = df.data\n",
        "y = df.target\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "# Split ds\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=50, random_state=25)\n",
        "print(x_train)\n",
        "print(x_test)\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "\n",
        "# Train\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "# Test/Predict\n",
        "y_train_pred = clf.predict(x_train)\n",
        "y_test_pred = clf.predict(x_test)\n",
        "\n",
        "# Evaluate Accuracy\n",
        "print(\"Train data accuracy:\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"Test data accuracy:\", accuracy_score(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "id": "cbksRBqg02sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**6.HOUSE PRICE PREDICTION:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ujR8VS1m1JKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "path = '/content/drive/MyDrive/dataset/homeprices.csv'\n",
        "df = pd.read_csv(path)\n",
        "print(df)\n",
        "\n",
        "print(df.info())\n",
        "print(len(df))\n",
        "print(len(df.columns))\n",
        "print(df.shape)\n",
        "print(df.size)\n",
        "print(df.shape[0])\n",
        "print(df.shape[1])\n",
        "roes,columns=df.shape\n",
        "print(columns)\n",
        "\n",
        "input = df.drop('price',axis=1)\n",
        "output = df.drop('area', axis=1)\n",
        "print(input)\n",
        "print(output)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.xlabel = ('area')\n",
        "plt.ylabel = ('price')\n",
        "plt.scatter(input,output,marker='*',color='red')\n",
        "plt.title('area vs price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yJ1YmXvb1R1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**7.Clustering:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "_1ZgjkhfeifH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#load\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataset/Clustering.csv')\n",
        "print(df)\n",
        "\n",
        "#preprocess: use numeric columns only\n",
        "X = df.select_dtypes(include='number')\n",
        "\n",
        "# Fill missing values with column mean\n",
        "X = X.fillna(X.mean()).values\n",
        "print(X)\n",
        "\n",
        "# Elbow curve\n",
        "plt.plot(range(1, 11), [KMeans(k, n_init=10, random_state=0).fit(X).inertia_ for k in range(1, 11)])\n",
        "plt.show()\n",
        "\n",
        "# KMeans (3 clusters)\n",
        "kmeans = KMeans(3, n_init=10, random_state=0).fit(X)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# Plot clusters + centroids using first 2 features\n",
        "for c in ['r', 'b', 'g']:\n",
        "    i = ['r', 'b', 'g'].index(c)\n",
        "    plt.scatter(X[labels == i, 0], X[labels == i, 1], c=c)\n",
        "\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
        "            c='y', marker='*', s=150)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9N0wsoslcfIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**8.K-MEANS**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JZ2CB8pzjWMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load\n",
        "path = ('/content/drive/MyDrive/dataset/kmeans.csv')\n",
        "df = pd.read_csv(path)\n",
        "print(df)\n",
        "\n",
        "# Prepare\n",
        "scaler = MinMaxScaler()\n",
        "df[['Age', 'Income($)']] = scaler.fit_transform(df[['Age', 'Income($)']])\n",
        "\n",
        "# Model\n",
        "kmeans = KMeans(n_clusters=3, random_state=0)\n",
        "\n",
        "#predict\n",
        "df['cluster'] = kmeans.fit_predict(df[['Age', 'Income($)']])\n",
        "\n",
        "\n",
        "# Visualize clusters & centroids\n",
        "centers = kmeans.cluster_centers_\n",
        "\n",
        "plt.scatter(df['Age'], df['Income($)'], c=df['cluster'])\n",
        "plt.scatter(centers[:, 0], centers[:, 1], marker='*', s=200, label='centroids')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Income($)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8eQGxOB4jURa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**9.LOGISTIC REGRESSION:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KtnonKB5iR-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load\n",
        "path=('/content/drive/MyDrive/dataset/logistic regression.csv')\n",
        "df = pd.read_csv(path)\n",
        "print(df)\n",
        "\n",
        "# Prepare\n",
        "X = df[['age']]\n",
        "y = df['bought_insurance']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Predicted:\", y_pred)\n",
        "print(\"Actual:\", y_test.values)\n"
      ],
      "metadata": {
        "id": "B4wJKDZWiYPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**10.SVM:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7_pLnbqvqYra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Load\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/dataset/svm model.csv\")\n",
        "\n",
        "# Prepare\n",
        "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
        "\n",
        "X = df[['Gender', 'Age', 'EstimatedSalary']]\n",
        "y = df['Purchased']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model\n",
        "model = SVC()\n",
        "\n",
        "# Train/Test\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Predicted:\", y_pred)\n",
        "print(\"Actual:\", y_test.values)"
      ],
      "metadata": {
        "id": "N5rR7g8AqWFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ0gOtMcHdVX",
        "outputId": "77349456-e0d1-4d13-95ed-8b76152e48bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cweZwAM-Hd1U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}