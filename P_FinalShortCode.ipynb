{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4gjXtjx6+s4vsQ5iEOFVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragyapriya-18/ai-ml-/blob/main/P_FinalShortCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "--#SHORT CODES FOR PR EXAM#--\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aO89gp3PhKLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**1.MNIST:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "XFEc2RKkhhGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess\n",
        "x_train = x_train.reshape(60000, 28*28) / 255\n",
        "x_test  = x_test.reshape(10000, 28*28) / 255\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=28*28, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# Train\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
        "\n",
        "# Test accuracy\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test Accuracy:\", acc)\n",
        "\n",
        "# Optional: Predict one sample\n",
        "y_pred = model.predict(x_test)\n",
        "print(\"Predicted digit:\", np.argmax(y_pred[0]))\n",
        "\n",
        "# Plot training accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# Plot training loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DScuLN8YhfZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**2.AND LOGIC GATE:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Vmdrm8D4w7oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Load\n",
        "path = \"/content/drive/MyDrive/dataset/and.csv\"\n",
        "df= pd.read_csv(path)\n",
        "print(df)\n",
        "\n",
        "# Prepare\n",
        "x = df.iloc[:,:2].values\n",
        "y = df.iloc[:,2:].values\n",
        "print(y)\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "model.add(Dense(16,input_dim=2,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Train\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])\n",
        "model.fit(x,y,epochs=250)\n",
        "\n",
        "\n",
        "# Predict\n",
        "print(model.predict(np.array([[1, 1]])))\n",
        "\n",
        "weights = model.get_weights()\n",
        "print(weights[1])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vhHkHUbNxb2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**3.IRIS CLASSIFIER:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ctvQsBmK0Yf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X8O9PfBidxG",
        "outputId": "5426867b-0727-46cd-e9dc-c6a8ebb19c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = to_categorical(iris.target, num_classes=3)\n",
        "\n",
        "# Prepare\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=4, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Train\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=250)\n",
        "\n",
        "# Test\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(acc)\n",
        "\n",
        "# Accuracy graph\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Loss graph\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_uZmmB_x0XnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**4.HANDLING MISSING VALUES:--**\n",
        "\n",
        "---\n",
        "\n",
        "Using isnull() and notnull()\n",
        "\n",
        "Using fillna(),bfill(),pad()\n",
        "\n",
        "Interpolate the missing values\n",
        "\n",
        "Using dropna()"
      ],
      "metadata": {
        "id": "VnNP7A6Q0j-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Given the following data:\n",
        "\n",
        "Create a DateFrame for the above data\n",
        "\n",
        "   First Score       Second Score            Third Score\n",
        "\n",
        "0     100                30                     np.nan\n",
        "\n",
        "1     90                 45                       40\n",
        "\n",
        "2    np.nan              56                       80\n",
        "\n",
        "3      95               np.nan                    98\n"
      ],
      "metadata": {
        "id": "Ilhmhvj5gTbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "dict={'First Score':[100,90,np.nan,95],\n",
        "      'Second Score':[30,45,56,np.nan],\n",
        "      'Third Score':[np.nan,40,80,98]}\n",
        "df=pd.DataFrame(dict)\n",
        "print(df)\n",
        "\n",
        "df.isnull()\n",
        "df.notnull()\n",
        "\n",
        "df.fillna(0)\n",
        "df.fillna(method='pad')\n",
        "df.fillna(method='bfill')\n",
        "\n",
        "df.interpolate(method='linear',limit_direction='forward')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "dict={'First Score':[100,90,np.nan,95],\n",
        "      'Second Score':[30,np.nan,45,56],\n",
        "      'Third Score':[52,40,80,98],\n",
        "      'Fourth Score':[np.nan,np.nan,np.nan,65]}\n",
        "df=pd.DataFrame(dict)\n",
        "print(df)\n",
        "df.dropna()"
      ],
      "metadata": {
        "id": "eWxXu8jF0jU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**5.DECISION TREE CLASSIFIER:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "h0nBb6Qc0upQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load\n",
        "df=load_iris()\n",
        "\n",
        "x = df.data\n",
        "y = df.target\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "# Prepare\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=50, random_state=25)\n",
        "print(x_train)\n",
        "print(x_test)\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "\n",
        "# Model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Train\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Evaluate Accuracy\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "cbksRBqg02sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**6.HOUSE PRICE PREDICTION:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ujR8VS1m1JKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "path = '/content/drive/MyDrive/dataset/homeprices.csv'\n",
        "df = pd.read_csv(path)\n",
        "print(df)\n",
        "\n",
        "print(df.info())\n",
        "print(len(df))\n",
        "print(len(df.columns))\n",
        "print(df.shape)\n",
        "print(df.size)\n",
        "print(df.shape[0])\n",
        "print(df.shape[1])\n",
        "roes,columns=df.shape\n",
        "print(columns)\n",
        "\n",
        "input = df.drop('price',axis=1)\n",
        "output = df.drop('area', axis=1)\n",
        "print(input)\n",
        "print(output)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.xlabel = ('area')\n",
        "plt.ylabel = ('price')\n",
        "plt.scatter(input,output,marker='*',color='red')\n",
        "plt.title('area vs price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yJ1YmXvb1R1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**7.Clustering:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "_1ZgjkhfeifH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load\n",
        "path =('/content/drive/MyDrive/dataset/Clustering.csv')\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# Keep only numeric columns\n",
        "df_numeric = df.select_dtypes(include=['int64', 'float64'])\n",
        "\n",
        "# Fix: Fill missing values\n",
        "df_numeric = df_numeric.fillna(0)\n",
        "\n",
        "# Convert to array\n",
        "X = df_numeric.values\n",
        "\n",
        "# Model\n",
        "kmeans = KMeans(n_clusters=3, random_state=0)\n",
        "y_kmeans = kmeans.fit_predict(X)\n",
        "\n",
        "# Visualize\n",
        "plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], c='red', label='Cluster 1')\n",
        "plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], c='blue', label='Cluster 2')\n",
        "plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], c='green', label='Cluster 3')\n",
        "\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0],\n",
        "            kmeans.cluster_centers_[:, 1],\n",
        "            marker='*', s=200, c='yellow', label='Centroids')\n",
        "\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9N0wsoslcfIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**8.K-MEANS:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JZ2CB8pzjWMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load\n",
        "path = ('/content/drive/MyDrive/dataset/kmeans.csv')\n",
        "df = pd.read_csv(path)\n",
        "print(df)\n",
        "\n",
        "# Prepare\n",
        "scaler = MinMaxScaler()\n",
        "df[['Age', 'Income($)']] = scaler.fit_transform(df[['Age', 'Income($)']])\n",
        "\n",
        "# Model\n",
        "kmeans = KMeans(n_clusters=3, random_state=0)\n",
        "\n",
        "#predict\n",
        "df['cluster'] = kmeans.fit_predict(df[['Age', 'Income($)']])\n",
        "\n",
        "\n",
        "# Visualize clusters & centroids\n",
        "centers = kmeans.cluster_centers_\n",
        "\n",
        "plt.scatter(df['Age'], df['Income($)'], c=df['cluster'])\n",
        "plt.scatter(centers[:, 0], centers[:, 1], marker='*', s=200, label='centroids')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Income($)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8eQGxOB4jURa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**9.LOGISTIC REGRESSION:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KtnonKB5iR-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load\n",
        "path=('/content/drive/MyDrive/dataset/logistic regression.csv')\n",
        "df = pd.read_csv(path)\n",
        "print(df)\n",
        "\n",
        "# Prepare\n",
        "X = df[['age']]\n",
        "y = df['bought_insurance']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Predicted:\", y_pred)\n",
        "print(\"Actual:\", y_test.values)\n",
        "\n",
        "# Plot\n",
        "plt.scatter(X_test, y_test)\n",
        "plt.plot(X_test, y_pred, color='red')\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Bought Insurance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B4wJKDZWiYPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**10.SVM:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7_pLnbqvqYra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Load\n",
        "path=(\"/content/drive/MyDrive/dataset/svm model.csv\")\n",
        "df = pd.read_csv(path)\n",
        "print(df)\n",
        "\n",
        "# Prepare\n",
        "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
        "\n",
        "X = df[['Gender', 'Age', 'EstimatedSalary']]\n",
        "y = df['Purchased']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model\n",
        "model = SVC()\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Predicted:\", y_pred)\n",
        "print(\"Actual:\", y_test.values)"
      ],
      "metadata": {
        "id": "N5rR7g8AqWFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uQ0gOtMcHdVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**11.STUDENT STUDY HR:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "w9BbzxT4QkB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/dataset/StudentStudyHour.csv\")\n",
        "\n",
        "# Prepare\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "X = df[['Hours']]\n",
        "y = df['Scores']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Predicted:\", y_pred)\n",
        "print(\"Actual:\", y_test.values)\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "id": "wH_ZA6HBM8MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**12.RANDOM FOREST REGRESSION:--**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "tfkLBAjgRxM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "# Load\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/dataset/random froest.csv')\n",
        "\n",
        "# Prepare\n",
        "X = dataset.drop('price', axis=1)\n",
        "y = dataset['price']\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# Model\n",
        "model = RandomForestRegressor(n_estimators=50, random_state=0)\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"MAE:\", metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE:\", metrics.mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "WydyQd_1Ruwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**13.IRIS DS:--**\n",
        "\n",
        "\n",
        "* View the first 5 rows of the dataframe\n",
        "* Compute and print the mean and standard deviation for each columns\n",
        "* Display all functions in iris data\n",
        "* Scatter plot\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Q75b4q-RSJ20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "\n",
        "# Load\n",
        "path = (\"/content/drive/MyDrive/dataset/Irisds.csv\")\n",
        "data = pd.read_csv(path)\n",
        "\n",
        "# First 5 rows\n",
        "data.columns = ['Id', 'sepal length','sepal width','petal length','petal width','Species']\n",
        "print(data.head())\n",
        "\n",
        "# Mean, Std, Min, Max\n",
        "for col in data:\n",
        "  if is_numeric_dtype(data[col]):\n",
        "    print('%s:' % col)\n",
        "    print('\\tMean= %.2f' % data[col].mean())\n",
        "    print('\\tStd = %.2f' % data[col].std())\n",
        "    print('\\tMin = %.2f' % data[col].min())\n",
        "    print('\\tMax = %.2f' % data[col].max())\n",
        "\n",
        "# Describe\n",
        "data.describe(include='all')\n",
        "\n",
        "#Plot\n",
        "fig, axes = plt.subplots(3, 2, figsize=(12, 12))\n",
        "index = 0\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i+1, 4):\n",
        "        ax = axes[index // 2][index % 2]\n",
        "        ax.scatter(data.iloc[:, i+1], data.iloc[:, j+1], color='red')\n",
        "        ax.set_xlabel(data.columns[i+1])\n",
        "        ax.set_ylabel(data.columns[j+1])\n",
        "        index += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SILTC5ZvJaWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57FXdjTQc67l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}